// my-scrape-project/src/scrape.ts
// âœ… WORKING VERSION - Angular app Ã¼Ã§Ã¼n

import type { Browser, Page, Locator } from 'playwright'; 
import { chromium } from 'playwright';
import { insertOrUpdateSupabase } from './supabase'; 

export interface ScrapedJobData {
Â  Â  title: string;
Â  Â  companyName: string; 
Â  Â  url: string;
Â  Â  salary: string;
Â  Â  siteUrl: string; 
}

const BASE_URL: string = 'https://www.workingnomads.com'; 
const TARGET_URL: string = `${BASE_URL}/jobs?postedDate=1`; 
const MAX_SCROLL_COUNT = 500; 

const SELECTORS = {
Â  Â  JOB_CONTAINER: '.job-wrapper',
Â  Â  TITLE_URL: 'h4.hidden-xs a',
Â  Â  COMPANY_CONTAINER: '.job-company', 
Â  Â  LIST_SALARY: 'div[ng-show*="model.salary_range"] span.about-job-line-text.ng-binding',
Â  Â  DETAIL_SALARY_A: '.job-details-inner div:has(i.fa-money)', 
Â  Â  DETAIL_SALARY_B: 'div.job-detail-sidebar:has(i.fa-money)',
};

async function scrapeDetailPageForSalary(browser: Browser, url: string): Promise<string> {
Â  Â  const detailPage = await browser.newPage();
Â  Â  let salary = 'N/A';

Â  Â  try {
Â  Â  Â  Â  await detailPage.goto(url, { timeout: 40000, waitUntil: 'domcontentloaded' });
Â  Â  Â  Â  const locatorA = detailPage.locator(SELECTORS.DETAIL_SALARY_A).filter({ hasText: '$' }).first();
Â  Â  Â  Â  const locatorB = detailPage.locator(SELECTORS.DETAIL_SALARY_B).filter({ hasText: '$' }).first();
Â  Â  Â  Â  let salaryText: string | null = null;
Â  Â  Â  Â  
Â  Â  Â  Â  try { salaryText = await locatorA.innerText({ timeout: 5000 }); } catch (e) {
Â  Â  Â  Â  Â  Â  try { salaryText = await locatorB.innerText({ timeout: 5000 }); } catch (e) { }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  if (salaryText && salaryText.includes('$')) {
Â  Â  Â  Â  Â  Â  const lines = salaryText.split('\n').map(line => line.trim()).filter(line => line.length > 0);
Â  Â  Â  Â  Â  Â  const salaryLine = lines.find(line => line.includes('$'));
Â  Â  Â  Â  Â  Â  salary = salaryLine ? salaryLine : salaryText.trim();
Â  Â  Â  Â  }

Â  Â  } catch (e) {
Â  Â  Â  Â  // Salary tapÄ±lmadÄ±
Â  Â  } finally {
Â  Â  Â  Â  await detailPage.close();
Â  Â  }
Â  Â  return salary;
}

async function extractInitialJobData(wrapper: Locator): Promise<ScrapedJobData> {
Â  Â  
Â  Â  const titleLocator = wrapper.locator(SELECTORS.TITLE_URL).first();
Â  Â  let title = '', relativeUrl = null, url = 'N/A', companyName = 'N/A', salary = 'N/A';
Â  Â  
Â  Â  try {
Â  Â  Â  Â  title = (await titleLocator.innerText({ timeout: 500 })).trim();
Â  Â  Â  Â  relativeUrl = await titleLocator.getAttribute('href');
Â  Â  Â  Â  url = relativeUrl ? `${BASE_URL}${relativeUrl}` : 'N/A';
Â  Â  } catch (e) {
Â  Â  Â  Â  return { title: '', companyName: 'N/A', url: 'N/A', salary: 'N/A', siteUrl: BASE_URL }; 
Â  Â  }

Â  Â  try {
Â  Â  Â  Â  const companyContainerLocator = wrapper.locator(SELECTORS.COMPANY_CONTAINER).first(); 
Â  Â  Â  Â  let rawText = (await companyContainerLocator.innerText({ timeout: 1000 })).trim(); 
Â  Â  Â  Â  let cleanedText = rawText.replace(/\s+/g, ' ').trim(); 
Â  Â  Â  Â  
Â  Â  Â  Â  const lowerCaseName = cleanedText.toLowerCase();
Â  Â  Â  Â  if (cleanedText.length > 2 && 
Â  Â  Â  Â  Â  Â  !lowerCaseName.includes('full-time') && 
Â  Â  Â  Â  Â  Â  !lowerCaseName.includes('remote') &&
Â  Â  Â  Â  Â  Â  !lowerCaseName.includes('jobs')) 
Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  companyName = cleanedText;
Â  Â  Â  Â  }

Â  Â  } catch (e) { 
Â  Â  Â  Â  companyName = 'N/A';
Â  Â  }
Â  Â  
Â  Â  if (companyName === 'N/A' || companyName.length < 3) {
Â  Â  Â  Â  const urlParts = url.split('-');
Â  Â  Â  Â  const companyIndex = urlParts.findIndex(part => /^\d{7}$/.test(part)); 
Â  Â  Â  Â  if (companyIndex > 0) {
Â  Â  Â  Â  Â  Â  let guess = urlParts[companyIndex - 1];
Â  Â  Â  Â  Â  Â  companyName = guess.charAt(0).toUpperCase() + guess.slice(1);
Â  Â  Â  Â  }
Â  Â  }
Â  Â  
Â  Â  try {
Â  Â  Â  Â  const salaryLocator = wrapper.locator(SELECTORS.LIST_SALARY).filter({ hasText: '$' }).first();
Â  Â  Â  Â  const salaryText = await salaryLocator.innerText({ timeout: 500 });
Â  Â  Â  Â  if (salaryText.includes('$') && salaryText.length > 5) {
Â  Â  Â  Â  Â  Â  salary = salaryText.trim();
Â  Â  Â  Â  }
Â  Â  } catch (e) { }

Â  Â  return { title, companyName, url, salary, siteUrl: BASE_URL };
}

export async function runScrapeAndGetData() {
Â  Â  
Â  Â  console.log(`\n--- WorkingNomads Scraper iÅŸÉ™ dÃ¼ÅŸdÃ¼ ---`);
Â  Â  console.log(`Naviqasiya edilir: ${TARGET_URL}`);
Â  Â  
Â  Â  const browser: Browser = await chromium.launch({ 
Â  Â  Â  Â  headless: true,
Â  Â  Â  Â  args: [
Â  Â  Â  Â  Â  Â  '--no-sandbox',
Â  Â  Â  Â  Â  Â  '--disable-setuid-sandbox',
Â  Â  Â  Â  Â  Â  '--disable-dev-shm-usage',
Â  Â  Â  Â  Â  Â  '--disable-gpu',
Â  Â  Â  Â  Â  Â  '--disable-blink-features=AutomationControlled',
Â  Â  Â  Â  ]
Â  Â  }); Â  Â 
Â  Â  
Â  Â  const context = await browser.newContext({
Â  Â  Â  Â  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
Â  Â  Â  Â  viewport: { width: 1920, height: 1080 },
Â  Â  });
Â  Â  
Â  Â  const page: Page = await context.newPage();
Â  Â  
Â  Â  await page.addInitScript(() => {
Â  Â  Â  Â  Object.defineProperty(navigator, 'webdriver', {
Â  Â  Â  Â  Â  Â  get: () => false,
Â  Â  Â  Â  });
Â  Â  });
Â  Â  
Â  Â  try {
Â  Â  Â  Â  console.log('â³ SÉ™hifÉ™ yÃ¼klÉ™nir...');
Â  Â  Â  Â  await page.goto(TARGET_URL, { 
Â  Â  Â  Â  Â  Â  timeout: 90000, 
Â  Â  Â  Â  Â  Â  waitUntil: 'domcontentloaded' 
Â  Â  Â  Â  });
Â  Â  Â  Â  console.log('âœ… SÉ™hifÉ™ DOM yÃ¼klÉ™ndi!');
Â  Â  Â  Â  
Â  Â  Â  Â  // âœ… ÆSAS HÆLL: Angular app-in baÅŸlamasÄ±nÄ± gÃ¶zlÉ™
Â  Â  Â  Â  console.log('â³ Angular app-in baÅŸlamasÄ± gÃ¶zlÉ™nilir...');
Â  Â  Â  Â  
Â  Â  Â  Â  // 1. Job container-lÉ™rin yÃ¼klÉ™nmÉ™sini gÃ¶zlÉ™ (DAHA UZUN TIMEOUT)
Â  Â  Â  Â  await page.waitForSelector(SELECTORS.JOB_CONTAINER, { 
Â  Â  Â  Â  Â  Â  timeout: 120000, // 2 dÉ™qiqÉ™
Â  Â  Â  Â  Â  Â  state: 'visible' 
Â  Â  Â  Â  });
Â  Â  Â  Â  
Â  Â  Â  Â  console.log('âœ… Angular app baÅŸladÄ± vÉ™ job-lar yÃ¼klÉ™ndi!');
Â  Â  Â  Â  
Â  Â  Â  Â  // 2. Ä°lk job-larÄ±n tam render olmasÄ±na vaxt ver
Â  Â  Â  Â  await page.waitForTimeout(3000);
Â  Â  Â  Â  
Â  Â  Â  Â  // 3. Ä°lk say-Ä± gÃ¶tÃ¼r
Â  Â  Â  Â  let initialCount = await page.locator(SELECTORS.JOB_CONTAINER).count();
Â  Â  Â  Â  console.log(`ğŸ“Š Ä°lk olaraq ${initialCount} job tapÄ±ldÄ±`);
Â  Â  Â  Â  
Â  Â  Â  Â  // âœ… SCROLL STRATEGIYASI: Angular infinite scroll iÅŸlÉ™mÉ™si Ã¼Ã§Ã¼n
Â  Â  Â  Â  let currentJobCount = initialCount;
Â  Â  Â  Â  let previousCount = 0;
Â  Â  Â  Â  let sameCountIterations = 0;
Â  Â  Â  Â  let scrollAttempts = 0;
Â  Â  Â  Â  const MAX_SCROLL_ATTEMPTS = 100;
Â  Â  Â  Â  
Â  Â  Â  Â  console.log('ğŸ”„ Infinite scroll aktivlÉ™ÅŸdirilir...\n');
Â  Â  Â  Â  
Â  Â  Â  Â  while (scrollAttempts < MAX_SCROLL_ATTEMPTS && sameCountIterations < 8) { 
Â  Â  Â  Â  Â  Â  // Smooth scroll (Angular-Ä±n scroll event-ini trigger edir)
Â  Â  Â  Â  Â  Â  await page.evaluate(() => {
Â  Â  Â  Â  Â  Â  Â  Â  window.scrollTo({ 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  top: document.body.scrollHeight, 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  behavior: 'smooth' 
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Angular-a yeni job-larÄ± yÃ¼klÉ™mÉ™yÉ™ vaxt ver
Â  Â  Â  Â  Â  Â  await page.waitForTimeout(3000);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  previousCount = currentJobCount;
Â  Â  Â  Â  Â  Â  currentJobCount = await page.locator(SELECTORS.JOB_CONTAINER).count();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  scrollAttempts++;
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (currentJobCount > previousCount) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`âœ… [${scrollAttempts}] Yeni job-lar yÃ¼klÉ™ndi: ${previousCount} â†’ ${currentJobCount}`);
Â  Â  Â  Â  Â  Â  Â  Â  sameCountIterations = 0;
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  sameCountIterations++;
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`â¸ï¸ Â [${scrollAttempts}] Yeni job yoxdur (${sameCountIterations}/8)`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // MAX_SCROLL_COUNT-a Ã§atdÄ±qsa dayan
Â  Â  Â  Â  Â  Â  if (currentJobCount >= MAX_SCROLL_COUNT) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`ğŸ¯ Maksimum limitÉ™ (${MAX_SCROLL_COUNT}) Ã§atÄ±ldÄ±!`);
Â  Â  Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 8 dÉ™fÉ™ yeni job gÉ™lmÉ™sÉ™, bitir
Â  Â  Â  Â  Â  Â  if (sameCountIterations >= 8) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`âœ… BÃ¼tÃ¼n job-lar yÃ¼klÉ™ndi (${currentJobCount} toplam)`);
Â  Â  Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  console.log(`\nğŸ“¦ ${currentJobCount} job-dan mÉ™lumat Ã§Ä±xarÄ±lÄ±r...\n`);
Â  Â  Â  Â  const jobWrappers = await page.locator(SELECTORS.JOB_CONTAINER).all();
Â  Â  Â  Â  
Â  Â  Â  Â  const initialResults: ScrapedJobData[] = [];
Â  Â  Â  Â  
Â  Â  Â  Â  for (let i = 0; i < jobWrappers.length; i++) {
Â  Â  Â  Â  Â  Â  const result = await extractInitialJobData(jobWrappers[i]);
Â  Â  Â  Â  Â  Â  initialResults.push(result);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Progress indicator
Â  Â  Â  Â  Â  Â  if ((i + 1) % 25 === 0) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(` Â  ğŸ“ ${i + 1}/${jobWrappers.length} elan iÅŸlÉ™ndi...`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  const validJobs = initialResults.filter(j => j.title.length > 0);
Â  Â  Â  Â  console.log(`\nâœ… ${validJobs.length} valid job tapÄ±ldÄ±`);
Â  Â  Â  Â  
Â  Â  Â  Â  // Salary scraping (detail page-dÉ™n)
Â  Â  Â  Â  console.log('\nğŸ’° Salary mÉ™lumatlarÄ± yoxlanÄ±lÄ±r...');
Â  Â  Â  Â  const finalResults: ScrapedJobData[] = []; 
Â  Â  Â  Â  let salaryCount = 0;
Â  Â  Â  Â  
Â  Â  Â  Â  for (let i = 0; i < validJobs.length; i++) {
Â  Â  Â  Â  Â  Â  const job = validJobs[i];
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (job.salary === 'N/A' && job.url.startsWith(BASE_URL)) {
Â  Â  Â  Â  Â  Â  Â  Â  const detailSalary = await scrapeDetailPageForSalary(browser, job.url);
Â  Â  Â  Â  Â  Â  Â  Â  if (detailSalary !== 'N/A') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  salaryCount++;
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  job.salary = detailSalary;
Â  Â  Â  Â  Â  Â  } else if (job.salary !== 'N/A') {
Â  Â  Â  Â  Â  Â  Â  Â  salaryCount++;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  finalResults.push(job);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Progress indicator
Â  Â  Â  Â  Â  Â  if ((i + 1) % 25 === 0) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(` Â  ğŸ’µ ${i + 1}/${validJobs.length} job yoxlanÄ±ldÄ± (${salaryCount} salary tapÄ±ldÄ±)`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  const filteredResults = finalResults.filter(job => job.url !== 'N/A');

Â  Â  Â  Â  console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
Â  Â  Â  Â  console.log("â•‘ Â  Â  SCRAPING NÆTÄ°CÆLÆRÄ° Â  Â  Â  Â  Â  Â  Â â•‘");
Â  Â  Â  Â  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
Â  Â  Â  Â  console.log(`\nâœ… Yekun: ${filteredResults.length} elan Ã§Ä±xarÄ±ldÄ±`);
Â  Â  Â  Â  console.log(`ğŸ’° Salary mÉ™lumatÄ±: ${salaryCount} elan`);
Â  Â  Â  Â  console.log(`ğŸ”„ Scroll cÉ™hdi: ${scrollAttempts}\n`);

Â  Â  Â  Â  await insertOrUpdateSupabase(filteredResults);

Â  Â  Â  Â  return filteredResults; 

Â  Â  } catch (e) {
Â  Â  Â  Â  console.error(`\nâŒ Æsas XÉ™ta: ${e instanceof Error ? e.message : String(e)}`);
Â  Â  Â  Â  
Â  Â  Â  Â  // Debug info
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const url = page.url();
Â  Â  Â  Â  Â  Â  console.log(`ğŸ“ Son URL: ${url}`);
Â  Â  Â  Â  Â  Â  await page.screenshot({ path: 'error-final.png', fullPage: true });
Â  Â  Â  Â  Â  Â  console.log('ğŸ“¸ Screenshot: error-final.png');
Â  Â  Â  Â  } catch {}
Â  Â  Â  Â  
Â  Â  Â  Â  throw e; 
Â  Â  } finally {
Â  Â  Â  Â  await browser.close();
Â  Â  Â  Â  console.log('--- Scraper bitdi ---\n');
Â  Â  }
} 